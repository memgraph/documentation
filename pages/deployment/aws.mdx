
---
title: Deploy Memgraph on AWS EC2 instance description: Learn how to deploy your
Memgraph instance on the AWS EC2 instance.
---

import { Card, Cards, Tabs, Tab } from 'nextra/components'

# Deploy Memgraph in AWS EC2 instance

This guide will show you how to deploy Memgraph on an AWS EC2 instance. The
guide will cover only the specific bits that are different from the general
deployment guide you can find for native [linux](./linux.mdx) or
[docker](./docker.mdx) deployments.

This guide assumes you have an AWS account and are familiar with the AWS
console. If you are not, you can follow the [AWS EC2
documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html).


## Crating a new EC2 instance 

The first step is to have an EC2 instance running on AWS, where you will deploy
Memgraph. Here are some guidelines for opening a new EC2 instance for memgraph. 

### Picking the OS 

When creating the EC2 instance, you need to pick the OS you wish to have on the
instance. If you are going to use the Memgraph native installation, you need to
pick a Linux distribution that Memgraph supports.

Memgraph supports the following Linux distributions:

- Ubuntu (20.04, 22.04)
- Fedora (38, 39)
- Debian (11, 12) 
- Centos (7, 9) 
- Amazon Linux (2)
- RedHat (7, 9)
- Rocky (9.3)

This way, you will manage the native installation of Memgraph, which can bring
some of the speed benefits. 

If you are going to use the Memgraph Docker image, you can pick any Linux
distribution you prefer, as long as you can run Docker on it.


### Picking the instance type

When creating the EC2 instance, you need to pick the instance type. The process
highly depends on your actuall workload. For heavy graph processing, consider
using instances with more CPU and memory. 

Memgraph, by default, stores all data in the RAM, if you are going to use the
default storage mode (`IN_MEMORY_TRANSACTIONAL` or `IN_MEMORY_ANALYTICAL`), make
a calculation [how much data you will
need]((/fundamentals/storage-memory-usage#calculate-storage-memory-usage)).
There is also an [easy-to-use
calulator](https://memgraph.com/enterprise#ram-calculator) for approximating
memory usage. The rule of thumb is to have double the memory of what your
storage would take. You can go with less if you do not have a demanding
workload.


AWS has specialized instances for [memory-optimized
workloads](https://docs.aws.amazon.com/ec2/latest/instancetypes/mo.html) wich
are designed for in-memory databases, data analytics, and other memory-intensive
applications. They also provide DDR5 memory, so you may consider using them to
optimize for better performance. 


### Setup the network

When creating the EC2 instance, you need to set up the network access and
security group. By default, the Memgraph uses port 7687 for the Bolt protocol.
You need to open this port for TCP traffic and to allow connections to Memgraph. 

If you change the default bolt port, make sure to update the security group
accordingly.

Also, if deploying the Memgraph for replication or clustering, the ports for the
replication and clustering should be open as well.


### Setup the storage 

When creating the EC2 instance, you need to set up the storage. By default
Memgraph stores all data to working RAM, but for the [persistency between
restarts](../fundamentals/data-durability) Memgraph uses the disk storage to
store snapshots, configurations, etc.

The sizing of the storage depends on the amount of data you are going to store
in your Memgraph instance, and the quantity of the snapshots you want to keep
alive. 

The general rule of thumb is to double the storage and then the amount of data
you will store. If you are going to store 100GB of data, you should have at
least 200GB of disk storage. 


## Installing Memgraph 

Depending on the way you want to deploy Memgraph, native or via Docker, you need
to follow the steps below: 

<Tabs items={["Docker" , "Linux"]}>

 <Tab> For example, if you are using Amazon Linux 2, you can follow the steps
 below to install Docker:

     ```bash
        sudo yum update -y
        sudo yum install docker -y
        sudo systemctl start docker
        # Add the user to the docker group
        sudo usermod -a -G docker $(whoami)
        newgrp docker
    ```
 Note that the steps above may vary depending on your Linux distribution.

 After the docker is installed, you can pull the Memgraph image and run it:

    ```bash
        docker run -p 7687:7687 memgraph/memgraph:latest
    ```

 This will run Memgraph on the default port 7687. You should be able to connect
    to it via [Memgraph Lab](../data-visualization) or via [client
 libraries](../client-libraries) using the bolt protocol. If you have an issue
 connecting to Memgraph remotely, make sure that the port 7687 is open in [the
 security group of your EC2 instance](#Setup-the-network). </Tab>

 <Tab>

 Depending on the Linux distribution you are using, you can follow the guide for
 installing Memgraph on each distribution: 

    - [Ubuntu](../getting-started/install-memgraph/ubuntu.mdx)
    - [Fedora](../getting-started/install-memgraph/fedora.mdx)
    - [Debian](../getting-started/install-memgraph/debian.mdx)
    - [Centos](../getting-started/install-memgraph/centos.mdx)
    - [Amazon Linux](../getting-started/install-memgraph/amazon-linux.mdx)
    - [RedHat](../getting-started/install-memgraph/redhat.mdx)
    - [Rocky](../getting-started/install-memgraph/rocky.mdx)

 </Tab> </Tabs>

## Manage Memgraph deployment

After Memgraph is installed and running on your EC2 instance, Memgraph
management in AWS is identical to the general guidelines that are described in
the form of a native Linux Memgraph or Docker container Memgraph. 

Depending on what you are using, you can follow the [Linux](./linux.mdx) or
[Docker](./docker.mdx) deployment guide for more information on how to manage
the Memgraph deployment.


# Next steps 

Memgraph also supports deployment in the Kubernetes environment. If you are
interested in deploying Memgraph in Kubernetes, you can follow the [Memgraph
Kubernetes installation
guide](../getting-started/install-memgraph/kubernetes.mdx). 
