---
title: Memgraph's AI ecosystem
description: Explore key features, such as community detection, node embeddings, and graph neural networks, alongside integrations with popular AI libraries like LangChain and LlamaIndex, to create powerful, data-driven GenAI solutions.
---

import { Callout } from 'nextra/components'
import { Cards } from 'nextra/components'
import {CommunityLinks} from '/components/social-card/CommunityLinks'

# Memgraph's AI ecosystem

AI drives a wide range of innovations, from machine learning (ML) models to
natural language processing (NLP) systems and beyond. These technologies
frequently intersect, enabling the creation of powerful applications with
Generative AI (GenAI), including advanced chatbots and agents.

## What you'll find here

This section of Memgraph’s documentation is your guide to using Memgraph for AI:

- [Building GenAI apps with GraphRAG](/ai-ecosystem/graph-rag): See how
  knowledge graphs enable more efficient and scalable RAG systems.
- [AI integrations with Memgraph](/ai-ecosystem/integrations): We have several
  integrations with popular AI frameworks to help you customize and build your
  own GenAI application from scratch. Some of the libraries that support
  Memgraph include **Model Context Protocol (MCP)**, **LangChain**,
  **LlamaIndex**, **Cognee** and **Mem0**.
- [GraphChat in Memgraph Lab](#graphchat): Explore how natural
  language querying (GraphChat) ties into the GraphRAG ecosystem, making complex
  graphs accessible to everyone.
- [Machine learning with Memgraph](/ai-ecosystem/machine-learning): Learn how
  Memgraph powers ML workflows with graph-powered insights.

## GraphChat

**GraphChat** enables you to ask natural language questions about your graph
data directly within Memgraph Lab. Instead of writing Cypher queries, simply
describe what you want to know and GraphChat handles query generation and
execution behind the scenes.

<Cards>
  <Cards.Card
    title="GraphChat documentation"
    href="/memgraph-lab/features/graphchat"
  />
</Cards>

{<h3 className="custom-header">GraphChat with GraphRAG</h3>} 

The engineering flow behind GraphChat involves a seamless process that combines
graph database querying with LLMs:

![graphchat-rag](/pages/ai-ecosystem/graphchat/graphchat-rag.png)

**1. Retrieve the graph schema**: GraphChat first fetches your graph schema from Memgraph to understand the data
structure and relationships.

**2. Send the question to the LLM**: Your natural language query and the graph schema are sent to the LLM for
processing.

**3. Generate the Cypher query**: The LLM generates a Cypher query tailored to your graph schema.

**4. Run the query in Memgraph**: The Cypher query is executed on Memgraph to retrieve results.

**5. Summarize the results**: The results (in JSON format) are sent back to the LLM, which summarizes them in
natural language.

This flow enables both **data aggregation** and **GraphRAG queries**. While GraphChat currently supports straightforward queries, more complex graph traversal capabilities are under development.


<CommunityLinks/>