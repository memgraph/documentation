---
title: Knowledge graph creation
description: Learn how to create, structure and optimize knowledge graphs using Memgraph, enabling graph-based data insights. 
---
import {CommunityLinks} from '/components/social-card/CommunityLinks'
import { Cards } from 'nextra/components'

# Knowledge graph creation

A **knowledge graph (KG)** is a structured representation of information where nodes and their relationships are organized to enable context between the data, reasoning, discovery, and insights. Knowledge graphs are the cornerstone of a **GraphRAG system**, enabling LLMs to deliver more accurate and context-rich results.

![kg-or-no](/pages/ai-ecosystem/graph-rag/knowledge-graph-creation/kg-or-no.jpg) 

## The role of knowledge graphs in GraphRAG

- **Relational understanding**: Knowledge graphs encode semantic relationships between entities, revealing hidden patterns and connections.
- **Data discovery**: Graph traversal enables uncovering trends and insights that are difficult to achieve in relational databases.
- **AI applications**: Power semantic search, recommendation engines and intelligent agent-driven workflows.
- **Query flexibility**: Allow complex, relationship-based queries with dynamic graph traversals.

> Critical Step: The success of your GraphRAG system heavily depends on the quality of your knowledge graph. Whether you’re starting with structured or unstructured data will determine your approach.
> 

## Knowledge graph creation

### Data modeling

A well-structured knowledge graph starts with effective [data modeling](/data-modeling). This step ensures that your graph represents your domain knowledge accurately and supports efficient querying.

### Why is data modeling crucial for GraphRAG?

- **Efficient retrieval**: Properly defined nodes, relationships, and properties enable accurate and efficient queries. The graph structure must reflect the actual domain knowledge, avoiding redundancy or ambiguity.
- **Providing context for LLMs**: A well-modeled graph encodes the right context, allowing LLMs to generate meaningful and relevant responses.
- **Supporting multi-hop reasoning**: Seamless traversal across multiple relationships is only possible with a structured graph design. Inefficient traversals can slow down query performance.
- **More flexible iteration**: A solid starting point allows for testing, refining, and improving retrieval strategies without reworking the entire graph.

Investing time in data modeling is essential for building a scalable, accurate and impactful GraphRAG system.

<Cards>
  <Cards.Card
    title="More about data modeling"
    href="/data-modeling"
  />
  <Cards.Card
    title="Knowledge graph modeling"
    href="/data-modeling/modeling-guides/model-a-knowledge-graph"
  />
</Cards>

### Structured data

Having data already structured is the **recommended approach** when creating a GraphRAG system. When dealing with **structured data** (e.g., CSV, JSON, Cypherl), you have the most control over how your knowledge graph is modeled. This control ensures high accuracy and relevance in your GraphRAG system.

Structured data allows you to define nodes, relationships, and properties explicitly, eliminating ambiguities that can arise when relying on automated tools or LLMs.

Steps for structured data:

1. Map nodes and relationships
2. Define properties. This includes adding metadata to nodes and relationships for richer context.
3. Import into Memgraph.

<Cards>
  <Cards.Card
    title="More about data migration"
    href="/data-migration"
  />
    <Cards.Card
    title="Import best practices"
    href="/data-migration/best-practices"
  />
</Cards>

### Unstructured data

Working with **unstructured data** (e.g. text, images or logs) requires additional preprocessing to create a valid knowledge graph. The process involves balancing automation and human oversight.

#### Simplest approach

Transforming unstructured data like text, images or logs into a structured knowledge graph requires additional steps. Tools like [LangChain](/ai-ecosystem/integrations#langchain) and [LlamaIndex](/ai-ecosystem/integrations#llamaindex) simplify this process by bridging the gap between unstructured data and graph databases like Memgraph.

For more information, refer to the following:

- [Improved Knowledge Graph Creation with LangChain and LlamaIndex](https://memgraph.com/blog/improved-knowledge-graph-creation-langchain-llamaindex)
- [Integrating Memgraph with LlamaIndex Building GenAI Apps](https://memgraph.com/blog/integrating-memgraph-llamaindex-genai-apps)
- [Constructing a Knowledge Graph with LlamaIndex and Memgraph](https://www.llamaindex.ai/blog/constructing-a-knowledge-graph-with-llamaindex-and-memgraph)
- [How to Build GenAI Apps with LlamaIndex and Memgraph](https://www.youtube.com/watch?v=CRc0yHsmCXA)

#### Production-ready approach

From our experience working with unstructured data, here’s what we recommend. For production-ready systems or when accuracy matters, you need a custom pipeline which may look something like this:

1. **Preprocessing** to clean and organize raw data for analysis.
2. **Named Entity Recognition (NER)** to identify and classify entities in the data.
3. **Relationship extraction** to detect and define connections between entities.
4. **Contextual understanding and disambiguation** to resolve ambiguities and ensure contextually accurate representations.
5. **Post-processing** to refine and validate the structured data before graph creation.

By following these steps, you can work towards making your knowledge graph more precise, factual and potentially better optimized for GraphRAG use cases.

Here’s an example: [How to Extract Entities and Build a Knowledge Graph with Memgraph and SpaCy](https://memgraph.com/blog/extract-entities-build-knowledge-graph-memgraph-spacy). 

To see how the concepts above can be applied in real-world scenarios, check out the [Knowledge retrieval](/ai-ecosystem/graph-rag/knowledge-retrieval) and [Examples and demos](/ai-ecosystem/graph-rag/examples-and-demos) pages as your next step.

<CommunityLinks/>
