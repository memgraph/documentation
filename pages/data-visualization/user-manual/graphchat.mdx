---
title: GraphChat
description: GraphChat is a feature within Memgraph Lab that allows users to query the Memgraph database using the English language instead of Cypher queries.
---

import { Callout } from 'nextra/components'


# GraphChat

The GraphChat allows you to query the database using the English language,
rather than Cypher queries.

All the LLM settings can be adjusted in the **Settings** section. GraphChat
supports various LLM connection options.

Before using GraphChat, ensure the following:

- The MAGE graph algorithm library is installed on your Memgraph instance
- The database is populated with your data.

### OpenAI

Use OpenAI's models for processing natural language queries. Set up a connection
to OpenAI by providing:
- A valid OpenAPI key connection

### Azure OpenAI

Set up a connection to Azure OpenAI by providing:

- `azureOpenApiVersion`: Your Azure OpenAI service version. [Find the list of
  versions
  here](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions).
- `azureOpenApiApiKey`: Your Azure OpenAI API key
- `azureOpenApiInstanceName`: Your Azure OpenAI instance name
- `azureOpenApiDeploymentName`: Your Azure OpenAI deployment name.

Additional Azure OpenAI integration details can be found in the [Azure OpenAI
documentation](https://js.langchain.com/docs/integrations/text_embedding/azure_openai).

### Ollama

For local LLM model setup, Ollama can be used:

- Provide the local endpoint URL, such as `http://localhost:11434`.

Learn more about Ollama and how to set it up for local LLM model use:

- [Ollama Home Page](https://ollama.com/)
- [Ollama GitHub Repository](https://github.com/ollama/ollama)
- [Ollama Docker Hub](https://hub.docker.com/r/ollama/ollama)

Ensure you follow the appropriate guidelines and documentation when setting up
these connections to take full advantage of the GraphChat capabilities within
Memgraph Lab.
