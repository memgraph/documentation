---
title: Vector search
description: Learn how to use vector search and manage vector indices in Memgraph.
---

import { Callout } from 'nextra/components'
import { Steps } from 'nextra/components'
import {CommunityLinks} from '/components/social-card/CommunityLinks'


# Vector search

Vector search, also known as vector similarity search or nearest neighbor
search, is a technique used to find the most similar items in a collection of
data based on their vector representations. Memgraph
implements a `READ_UNCOMMITTED` isolation level specifically for vector indices.
While the main database can operate at any isolation level, the vector index
specifically operates at `READ_UNCOMMITTED`. This design maintains all
transactional guarantees at the database level. Only the vector index
operations use this relaxed isolation level, ensuring the database's ACID
properties remain intact for all other operations.

<Callout type="warning">
To configure vector search as described in the example, please use the latest Memgraph version.
</Callout>

Vector search is commonly used as a [retrieval
technique](/ai-ecosystem/graph-rag/knowledge-retrieval#vector-search) in RAG
systems to find entities based on semantic similarity rather than exact matches. 

![vector-search-workflow](/pages/querying/vector-search/vector-search-workflow.png)

## Create vector index 

To run vector search, first create vector index. 
Vector indices are created with the `CREATE VECTOR INDEX` command. 
To create the vector index, you need to:
1. Provide the index name
2. Specify the label and property it applies to
3. Define the vector index configuration

Here is an example:

```shell
CREATE VECTOR INDEX vector_index_name ON :Label(embedding) WITH CONFIG {"dimension": 256, "capacity": 1000};
```

Note that `dimension` and `capacity` are mandatory configuration required to create a vector index.

### Multiple vector indices per label and property

Users can create multiple vector indices per label and property. A use case for that can be providing vector indices with 
different metrics operating on same set of vertices.

### Configuration parameters

Below is a list of all configuration options:

- `dimension: int` ➡ The dimension of vectors in the index.
- `capacity: int` ➡ Minimum capacity for the vector index, which prefers powers of two and is adjusted internally for optimal performance but will be at least the given value.
- `metric: string (default=l2sq)` ➡ The metric used for the vector search. The default value is `l2sq` (squared Euclidean distance).
- `resize_coefficient: int (default=2)` ➡ When the index reaches its capacity, it resizes by multiplying the current capacity by this coefficient, if sufficient memory is available. 
If resizing fails due to memory limitations, an exception will be thrown. Default value is `2`.

## Run vector search

To run vector search, you need to call `vector_search` query module. 

<Callout type="info">

Unlike other index types, the query planner currently does not utilize vector indices.

</Callout>

### Show vector indices

To retrieve information about vector indices, use `vector_search.show_index_info()` procedure.

{<h3 className="custom-header"> Output: </h3>}

- `index_name: string` ➡ The name of the vector index.
- `label: string` ➡ The name of the label on which vector index is indexed.
- `property: string` ➡ The name of the property on which vector index is indexed.
- `dimension: int` ➡ The dimension of vectors in the index.
- `capacity: int` ➡ The capacity of the vector index.
- `size: int` ➡ The number of entries in the vector index.

{<h3 className="custom-header"> Usage: </h3>}

```shell
CALL vector_search.show_index_info() YIELD * RETURN *;
```

### Query vector index

Use the `vector_search.search()` procedure to search for similar vectors within
a vector index. This procedure allows you to find the closest vectors to a query
vector based on the selected similarity metric.

{<h3 className="custom-header"> Input: </h3>}

- `index_name: string` ➡ The vector index to search.
- `limit: int` ➡ The number of nearest neighbors to return.
- `search_query: List[float]` ➡ The vector to query in the index.

{<h3 className="custom-header"> Output: </h3>}

- `distance: double` ➡ The distance from the node to the query.
- `node: Vertex` ➡ A node in the vector index matching the given query.
- `similarity: double` ➡ The similarity of the node and the query.

{<h3 className="custom-header"> Usage: </h3>}

```shell
CALL vector_search.search("index_name", 1, [2.0, 2.0]) YIELD * RETURN *;
```

### Similarity metrics

The following table lists the supported similarity metrics for vector search. These
metrics determine how similarities between vectors are calculated. Default type
for the metric is `l2sq` (squared Euclidean distance).

| Metric      | Description                                          |
|-------------|------------------------------------------------------|
| `ip`        | Inner product (dot product)                         |
| `cos`       | Cosine similarity                                   |
| `l2sq`      | Squared Euclidean distance                          |
| `pearson`   | Pearson correlation coefficient                     |
| `haversine` | Haversine distance (suitable for geographic data)   |
| `divergence`| A divergence-based metric                           |
| `hamming`   | Hamming distance                                    |
| `tanimoto`  | Tanimoto coefficient                                |
| `sorensen`  | Sørensen-Dice coefficient                           |
| `jaccard`   | Jaccard index                                       |

### Scalar type

Properties are stored as 64-bit values in the property store and as 32-bit values in the vector index.
Scalar type define the data type of each vector element. Default type for the
metric is `f32`.

## Drop vector index

Vector indices are dropped with the `DROP VECTOR INDEX` command. You need to give the name of the index to be deleted.

```shell
DROP VECTOR INDEX vector_index_name;
```

## Example

Here is a simple example of vector search usage. 

<Steps>
{<h3 className="custom-header"> Run Memgraph and Lab </h3>}

First run Memgraph MAGE with the vector search enabled and configured with the following Docker command:

``` 
docker run -p 7687:7687 -p 7444:7444 memgraph/memgraph-mage:latest
```

Then, run [Memgraph Lab](/data-visualization/install-and-connect), a visual user interface:

```
docker run -p 3000:3000 memgraph/lab:latest 
```

You can also run Memgraph's CLI, [mgclient](/getting-started/cli), directly from
the Memgraph MAGE Docker container. 

{<h3 className="custom-header"> Create vector index </h3>}
 
After Memgraph MAGE and Lab have been started, head over to the Query execution
tab in Memgraph Lab and run the following query to create vector index:

```cypher
CREATE VECTOR INDEX index_name ON :Node(vector) WITH CONFIG {"dimension": 2, "capacity": 1000, "metric": "cos","resize_coefficient": 2};
```

Then, run the following query to inspect vector index:
```cypher
CALL vector_search.show_index_info() YIELD * RETURN *;
```

The above query will result with:

```
+--------------+--------------+--------------+--------------+--------------+--------------+
| capacity     | dimension    | index_name   | label        | property     | size         |
+--------------+--------------+--------------+--------------+--------------+--------------+
| 2048         | 2            | "index_name" | "Node"       | "vector"     | 0            |
+--------------+--------------+--------------+--------------+--------------+--------------+
```

{<h3 className="custom-header"> Create a node </h3>}

The next step is to create a node, with `Node` label and `vector` property, so it's
properly added to the vector index.

```cypher
CREATE (n:Node {vector: [2, 2]});
```

To confirm that the above node has been indexed, let's check the vector index info again:

```cypher
CALL vector_search.show_index_info() YIELD * RETURN *;
```

The above query results in:

```
+--------------+--------------+--------------+--------------+--------------+--------------+
| capacity     | dimension    | index_name   | label        | property     | size         |
+--------------+--------------+--------------+--------------+--------------+--------------+
| 2048         | 2            | "index_name" | "Node"       | "vector"     | 1            |
+--------------+--------------+--------------+--------------+--------------+--------------+
```

We can see the size of the index changed, due to one new node.

{<h3 className="custom-header"> Query vector index </h3>}

Let's search for the similar nodes. Here is an example query to do that:

```cypher
CALL vector_search.search("index_name", 1, [2.0, 2.0]) YIELD * RETURN *;
```

We expect to get the most similar node to vector `[2.0, 2.0]`:

```
+--------------------------+--------------------------+--------------------------+
| distance                 | node                     | similarity               |
+--------------------------+--------------------------+--------------------------+
| -1.19209e-07             | (:Node {vector: [2, 2]}) | 1                        |
+--------------------------+--------------------------+--------------------------+
```

The distance is 0 because the two vectors that are being compared with Cosine similarity are the same, leading to the similarity value of 1. 

{<h3 className="custom-header"> Add more nodes and expand search </h3>}

Let's add a couple of more nodes:

```cypher
CREATE (n:Node {vector: [1, 2]});
CREATE (n:Node {vector: [1, 1]});
CREATE (n:Node {vector: [0, 1]});
CREATE (n:Node {vector: [0, 0]});
```

Let's see the status of the index now:

```cypher
CALL vector_search.show_index_info() YIELD * RETURN *;
```

The size is now 5, due to 4 additional nodes:
```
+--------------+--------------+--------------+--------------+--------------+--------------+
| capacity     | dimension    | index_name   | label        | property     | size         |
+--------------+--------------+--------------+--------------+--------------+--------------+
| 2048         | 2            | "index_name" | "Node"       | "vector"     | 5            |
+--------------+--------------+--------------+--------------+--------------+--------------+
```

Let's again search for the top five similar nodes to the vector [2.0, 2.0] (to compare it to all nodes we have):

```cypher
CALL vector_search.search("index_name", 5, [2.0, 2.0]) YIELD * RETURN *;
```

Notice how we changed the limit to get the top five nearest neighbors. Here are the results:

```
+--------------------------+--------------------------+--------------------------+
| distance                 | node                     | similarity               |
+--------------------------+--------------------------+--------------------------+
| -1.19209e-07             | (:Node {vector: [1, 1]}) | 1                        |
| -1.19209e-07             | (:Node {vector: [2, 2]}) | 1                        |
| 0.0513167                | (:Node {vector: [1, 2]}) | 0.948683                 |
| 0.292893                 | (:Node {vector: [0, 1]}) | 0.707107                 |
| 1                        | (:Node {vector: [0, 0]}) | 0                        |
+--------------------------+--------------------------+--------------------------+
```

Since cosine similarity was used as a metric, we have two nodes with the same
similarity to the query vector: [1, 1] and [2, 2]. 

</Steps>

<CommunityLinks/>