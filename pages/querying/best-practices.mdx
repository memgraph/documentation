---
title: Querying best practices
description: Learn best querying techniques for Memgraph.
---

import { Card, Cards } from 'nextra/components'
import GitHub from '/components/icons/GitHub'

# Querying best practices


## Take advantage of the query plan


## How to speed up query execution

### Query parametrization


### Indexing

Indexing best practices in general + index hinting + analyze graph as strategies

### Reduce roundtrip

Usually, when writing a query, you're focused on the matching part more than on
the return part of the query. It is important to be expressive in the Cypher
query to find what you're looking for and to make the search area smaller with
each step to improve performance. But, the **return part of the query plays an
important role** as well, **affects the full roundtrip** and it shouldn't be
ignored. Each client spends some amount of time to send a query and to show the
results. When running queries with Memgraph Lab, this time is called Lab full
roundtrip and for each query, you can see that time along with the actual
Memgraph execution time, which includes query parsing, planning and running.

Too much time is spent on a full roundtrip when **everything** is returned as a
query result. If you don't need all the data from the query result, **return the
important subset of results**. Returning all paths along with node and
relationship properties affects full roundtrip, especially if your data has many
properties. That happens because all of the information must be fetched. If
possible, it's always better to **return only node property** (such as `id`). If
you're interested only in the count of returned records, **use `count()` to
reduce the full roundtrip**. Similarly, to get the length of returned lists of
nodes or relationships, use `size()` function.

By **using projection** in the return clause, you can **avoid returning
duplicates of nodes** and consequently reduce the full roundtrip.

Let's show how that works on a couple of examples on the Game of Thrones deaths
dataset from Memgraph Lab.

Here is an example query that returns the whole path:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
RETURN path;
```

When run in Memgraph Lab, **the full roundtrip is 82 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-1.png)

{<h4>Project to avoid duplicates</h4>} 
To speed up roundtrip, projection can be used to avoid returning node
duplicates. Here is a query that utilizes projection:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
WITH project(path) AS subgraph
RETURN subgraph;
```

When run in Memgraph Lab, **the full roundtrip is down to 49 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-2.png)

{<h4>Return a single value</h4>} 
Here is a query that returns only the number of paths:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
RETURN count(path);
```

When run in Memgraph Lab, **the full roundtrip is down to 30 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-3.png)

Similarly, `size()` and `sum()` functions can be used to speed up the full
roundtrip:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
WITH size(nodes(path)) as nodes, size(relationships(path)) AS relationships
RETURN sum(nodes), sum(relationships);
```

When run in Memgraph Lab, **the full roundtrip is down to 33 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-6.png)

Here is an example of using both `project()` and `size()`:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
WITH project(path) as subgraph
RETURN size(subgraph.nodes), size(subgraph.edges);
```

When run in Memgraph Lab, **the full roundtrip is down to 31 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-7.png)

{<h4>Return only a property</h4>} 

Here is a query that extracts nodes' internal ids from the path:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
WITH extract(n IN nodes(path) | ID(n)) AS nodes_ids
RETURN nodes_ids;
```

When run in Memgraph Lab, **the full roundtrip is down to 41 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-4.png)

Similarly, the following query returns only `name` nodes' property from the path:
```cypher
MATCH path=(:Character { name: "Jon Snow" })-[:KILLED *bfs]->(:Character)
WITH extract(n IN nodes(path) | n {.name}) AS nodes_ids
RETURN nodes_ids;
```

When run in Memgraph Lab, **the full roundtrip is down to 31 ms**. 

![](/pages/querying/best-practices/query-optimization-lab-got-5.png)

These are some of the tips that can help to reduce the roundtrip time. **On larger
datasets, these optimization strategies have larger impact and should be
utilized whenever possible to achieve the best performance**. 

## Fast deep-path traversals
In contrast to other graph databases, Memgraph deep-path traversals efficiently 
handle complex graph queries, as these algorithms have been built into Memgraph's 
core. This eliminates the need for the overhead of business logic on the 
application side.

### Available built-in algorithms
There are four built-in deep path traversal algorithms: Depth-first search (DFS), 
Breadth-first search (BFS), Weighted Shortest Path and All Shortest Paths.
Below are provided basic examples and usages of these algorithms. For more 
detailed explanation, visit the 
[documentation](/advanced-algorithms/built-in-graph-algorithms). 

#### Depth-first search 
The DFS algorithm starts at the root node and explores each neighboring node as 
far as possible. The moment it reaches a dead-end, it backtracks until it finds 
a new, undiscovered node, then traverses from that node to find more undiscovered 
nodes. In that way, the algorithm visits each node in the graph.

The following query will show all the paths from node `n` to node `m`:

```cypher
MATCH path=(n {id: 0})-[*]->(m {id: 8})
RETURN path;
```

**When to use DFS?** <br/>
DFS returns all of the found paths between given nodes and is the most suitable 
for determining **path existance** between two nodes in a graph. If the output of
the algorithm is null, there are no available paths between the nodes. If the output
is not null, the DFS algorithm is going to provide all possible paths as a result.


#### Breadth-first search
In BFS, traversal starts from a single node, and the order of visited nodes is 
decided based on nodes' breadth (distance from the source node). This means that 
when a certain node is visited, it can be safely assumed that all nodes that are 
fewer relationships away from the source node have already been visited, resulting 
in the shortest path from the source node to the newly visited node.

The following query will show the shortest path between nodes `n` and `m`:

```cypher
MATCH path=(n {id: 0})-[*BFS]->(m {id: 8})
RETURN path;
```

**When to use BFS?** <br/>
BFS is ideal for finding the **shortest path** between two nodes in an unweighted 
graph or between the start node and any other node in the graph. Since it traverses 
all nodes at a given depth before moving to the next level, it ensures that the 
shortest path is found.


#### Weighted shortest path
In graph theory, the weighted shortest path problem is the problem of finding a 
path between two nodes in a graph such that the sum of the weights of relationships 
connecting nodes, or the sum of the weight of some node property on the path, is 
minimized.

To find the weighted shortest path between nodes based on the value of the 
`total_USD` node property, traversing only across `CLOSE_TO` relationships and 
return the result as a graph, use the following query:

```cypher
MATCH path=(n {id: 0})-[:CLOSE_TO *WSHORTEST (r, n | n.total_USD)]-(m {id: 15})
RETURN path;
```

**When to use WSP?** <br/>
Use the weighted shortest path algorithm when you need to find the **shortest path** 
between two nodes in a graph with **weighted** edges. This is particularly useful 
in scenarios where the cost or distance between nodes varies, such as road networks 
(where edges represent distances or travel times) or communication networks 
(where edges represent latency or cost).

When the goal is to **optimize** a specific metric along the path (e.g., minimizing 
cost, maximizing profit), a weighted shortest path algorithm can help find the path 
that optimizes that metric.


#### All shortest paths
Finding all shortest paths is an expansion of the weighted shortest paths problem. 
The goal of finding the shortest path is obtaining any minimum sum of weights on 
the path from one node to the other. However, there could be multiple 
similar-weighted paths, and this algorithm fetches them all.

The following query searches for all shortest paths with a default weight equal to 1:

```cypher
MATCH path=(n {id: 0})-[:CloseTo *ALLSHORTEST (r, n | 1)]-(m {id: 15})
RETURN path;
```

**When to use ASP?** <br/>
Use the all shortest paths algorithm when you need to find all shortest paths between 
nodes in a graph with weighted edges. This is useful when you need to analyze the 
network structure or when there may be multiple identical shortest paths between 
pairs of nodes with minimum cost.

<br/>

<Cards>
    <Card
    title="Read more about built-in algorithms"
    href="/advanced-algorithms/built-in-graph-algorithms"
    />
</Cards>


### Optimizing graph traversals
Deep path traversal algorithms play a crucial role in exploring and analyzing 
graph data. In Memgraph, a powerful graph database management system, optimizing 
these algorithms can significantly enhance performance when dealing with 
large-scale graph structures. 

Let's dive into some strategies for optimizing traversal algorithms in Memgraph, 
along with providing examples using Cypher queries.

For example, let's take the following unoptimized query that traverses through the 
European transportation network. Using the BFS algorithm, we'll find all of the cities 
London is connected to with the shortest road path available. In other words, we'll 
find all shortest paths from the starting node with the `name` property being `London` 
to all of the nodes in the dataset. 

```cypher
MATCH path=(:City {name: 'London'})-[*BFS]->(:City)
RETURN path;
```

This query returns nodes representing cities London is connected to with the 
transportation network. 

Since we didn't provide any restrictions and filtering, the algorithm scans and 
traverses through entire dataset which can lead to slower performance on a larger 
scale datasets.


#### Creating indexes
Creating indexes on relevant properties can drastically speed up traversal queries 
by shortening the database scanning time. In Memgraph, indexes can be created 
using Cypher queries like:

```cypher
CREATE INDEX ON :Node(property)
```

This query creates an index on the property of nodes, enabling faster lookups 
during algorithm traversals.

<Cards>
    <Card
    title="Read more about indexing"
    href="/fundamentals/indexes"
    />
</Cards>
 

#### Filtering by relationship type

Unlike other graph databases, Memgraph supports inline filtering, enabling efficient 
traversal through graph structures. This approach allows for precise control over 
how relationships are traversed, including filtering by type and the direction
of relationship, avoiding subsequent filtering using the `WHERE` clause.

Let's take the same example from above, but this time limiting traversal across 
roads only, eliminating other types of transportation. In other words, we'll provide
relationship type filter to the previously used query and limit it only to traverse
through the relationship type `ROAD`.

```cypher
MATCH path=(:City {name: 'London'})-[r:ROAD *BFS]->(:City)
RETURN path;
```

This way, Memgraph eliminates traversing through unnecessary relationships, shortening
the execution time. 


#### Filtering by property value 
Traversal algorithms allow an expression filter that determines if an expansion 
is allowed over a certain relationship or node property value. 

Let's take the same example from above, but this time limiting traversal through 
the European roads only. We want to apply filter to the relationship property
`continent` and set the value to exactly `Europe`. 

```cypher
MATCH path=(:City {name: 'London'})-[r:ROAD *BFS (r, n | r.continent = 'Europe')]->(:City)
RETURN path;

```

This way, Memgraph eliminates traversing through unnecessary relationships and 
property values, shortening the execution time even more. 


#### Constraining path length
By constraining the length of the path, the algorithm won't do unnecessary scanning
and return results after finding results with the maximum number of hops.

The following query will only return the results if the path is equal to or shorter
than 2 hops:

```cypher
MATCH path=(:City {name: 'London'})-[r:ROAD *BFS ..2 (r, n | r.continent = 'Europe')]->(:City)
RETURN path;
```

By knowing the schema of your dataset and filtering and limiting the wanted results, 
you can achieve much more optimized way of using the traversal algorithms.

## Most common pitfalls
Examples from Mrma's video

### Cartesian product queries consuming too much memory

Cartesian product is by default enabled in Memgraph, and it enforces the usage of
the `Cartesian` operator.

Let's say we create the following dataset consisting of 1001 nodes where each
node has a property `id`:
```cypher
FOREACH (i in range(1, 1000) | CREATE (:Node {id: i}));
```

Here is an example of a query on that dataset that utilizes the `Cartesian`
operator:

```cypher
MATCH (n) 
MATCH (m) 
WHERE n.id > 500 and m.id > 500 
RETURN n, m;
```

If we profile the above query, we get:

```
+---------------------+---------------------+---------------------+---------------------+
| OPERATOR            | ACTUAL HITS         | RELATIVE TIME       | ABSOLUTE TIME       |
+---------------------+---------------------+---------------------+---------------------+
| "* Produce {n, m}"  | 250001              | " 74.600388 %"      | " 20.998413 ms"     |
| "* Cartesian"       | 250001              | " 21.847559 %"      | "  6.149620 ms"     |
| "|\\"               | ""                  | ""                  | ""                  |
| "| * Filter {n.id}" | 501                 | "  1.263678 %"      | "  0.355698 ms"     |
| "| * ScanAll (n)"   | 1001                | "  0.271637 %"      | "  0.076460 ms"     |
| "| * Once"          | 2                   | "  0.000375 %"      | "  0.000106 ms"     |
| "* Filter {m.id}"   | 501                 | "  1.724720 %"      | "  0.485472 ms"     |
| "* ScanAll (m)"     | 1001                | "  0.291143 %"      | "  0.081950 ms"     |
| "* Once"            | 2                   | "  0.000500 %"      | "  0.000141 ms"     |
+---------------------+---------------------+---------------------+---------------------+
```

Notice how, in the first case, the `ScanAll` operator has 1001 hits in the left
branch and 1001 hits in the right branch. The `Cartesian` operator filters
both branches and reduces the cardinality of the rows before
coming into the final operator, `Produce`, which streams the results.

If the Cartesian product was disabled by setting `--cartesian-product-enabled`
to `false`, this would be the result of the profile query:

```
+--------------------+--------------------+--------------------+--------------------+
| OPERATOR           | ACTUAL HITS        | RELATIVE TIME      | ABSOLUTE TIME      |
+--------------------+--------------------+--------------------+--------------------+
| "* Produce {n, m}" | 250001             | " 19.075343 %"     | " 16.333268 ms"    |
| "* Filter {n.id}"  | 250001             | " 65.714022 %"     | " 56.267649 ms"    |
| "* ScanAll (n)"    | 500001             | " 14.875191 %"     | " 12.736886 ms"    |
| "* Filter {m.id}"  | 501                | "  0.287328 %"     | "  0.246024 ms"    |
| "* ScanAll (m)"    | 1001               | "  0.048061 %"     | "  0.041152 ms"    |
| "* Once"           | 2                  | "  0.000056 %"     | "  0.000048 ms"    |
+--------------------+--------------------+--------------------+--------------------+
```


Without the Cartesian product, the first `ScanAll` would have 1001 hits, but the
second `ScanAll` would have 500001 hits. That's why the Cartesian product is so
powerful and, by default, enabled in Memgraph.

Still, **memory overhead** is a potential downside of the Cartesian product. The
results produced from the left branch (first below the `Cartesian` operator) are
cached for further use after the results of the right branch are ready. If the
left branch produces too many records, cache is being filled quickly, causing
large memory consumption.

To avoid memory overhead, there are two options:
1. **Switch the branches**: You can switch the order in which you're matching, so
   the branch with fewer records produces gets cached. 
2. **Set `--cartesian-product-enabled` to `false`**: If both branches cache a lot of
   results, then you can't avoid memory overhead by switching the branches. In that case, the
   need for memory resources is larger than the benefit of the
   performance gained by using the `Cartesian` product, so it's best to [disable
   it](/configuration/configuration-settings#during-runtime). 
