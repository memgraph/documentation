---
title: Memgraph in GraphRAG use cases
description: Suggestions on how to bring your Memgraph to production in GraphRAG use cases. 
---

import { Callout } from 'nextra/components'
import { CommunityLinks } from '/components/social-card/CommunityLinks'

# Memgraph in GraphRAG use cases

<Callout type="info">
üëâ **Start here first**  
Before diving into this guide, we recommend starting with the [**General suggestions**](/memgraph-in-production/general-suggestions) 
page. It provides **foundational, use-case-agnostic advice** for deploying Memgraph in production.

This guide builds on that foundation, offering **additional recommendations tailored to specific workloads**. 
In cases where guidance overlaps, consider the information here as **complementary or overriding**, depending 
on the unique needs of your use case.
</Callout>

## Is this guide for you?

This guide is for you if you're working with **high-throughput graph workloads** where performance, consistency,
and scale are critical.
You‚Äôll benefit from this content if:

- ‚ö° You‚Äôre handling **more than a thousand writes per second**, and your graph data is constantly changing at high velocity.  
- üîç You want your **read performance to remain consistent**, even as new data is continuously ingested.  
- üîÅ You‚Äôre dealing with **high volumes of concurrent reads and writes**, and need a database that can handle both without performance degradation.  
- üåä Your data is flowing in from **real-time streaming systems** like **Kafka**, and you need a database that can keep up.  

If this sounds like your use case, this guide will walk you through how to configure and scale Memgraph for **reliable, high-throughput performance** in production.

## Why choose Memgraph for high-throughput use cases?

When your workload involves thousands of writes per second and concurrent access to ever-changing graph data, 
Memgraph provides the performance and architecture needed to keep up‚Äîwithout compromise. 

Here's why Memgraph is a great fit for high-throughput use cases:

- **In-memory storage engine**  
  Memgraph doesn't need to write to disk on every transaction, enabling it to **scale write throughput far beyond traditional 
  disk-based databases**. Unlike systems that rely on LRU or OS-level caching‚Äîwhere **cache invalidation can degrade
  read performance during heavy writes**, Memgraph offers **predictable read latency** even under constant data changes.  
  
  While many graph databases **max out around 1,000 writes per second**, Memgraph can handle **up to 50x more** (image below),
  making it ideal for **high-velocity, write-intensive workloads**. 

  ![](/pages/memgraph-in-production/benchmarking-memgraph/realistic-workload.png)

- **Non-blocking reads and writes with MVCC**  
  Built on **multi-version concurrency control (MVCC)**, Memgraph ensures that **writes don‚Äôt block reads** and
  **reads don‚Äôt block writes**, allowing each to scale independently.

- **Fine-grained locking**  
  Locking happens at the **node and relationship level**, enabling **highly concurrent writes** and minimizing
  contention across threads.

- **Lock-free skiplist storage**  
  Memgraph uses **lock-free, concurrent skiplist structures** for storing nodes, relationships, and indices, leading to
  faster data access and minimal coordination overhead between threads.

- **Snapshot isolation by default**  
  Unlike many databases that rely on **read-committed** isolation (which can return inconsistent data), Memgraph provides
  **snapshot isolation**, ensuring data accuracy and consistency in real-time queries.

- **Inter-query parallelization**  
  Each read and write query is handled on its own CPU core, meaning Memgraph can **scale horizontally on a
  single machine** based on your hardware.

- **Horizontal read scaling with high availability**  
  Memgraph supports **replication and high availability**, allowing you to distribute **read traffic across multiple replicas**.
  These replicas can also power **secondary workloads** like GraphRAG, analytics, or ML pipelines, **without affecting
  the performance of the main write-intensive instance**.

## What is covered?

The suggestions for high-throughput workloads **complement** several key sections in the 
[general suggestions guide](/memgraph-in-production/general-suggestions). These sections offer important context and
additional best practices tailored for performance, stability, and scalability in high-throughput systems:

- [Choosing the right Memgraph flag set](#choosing-the-right-memgraph-flag-set) <br />
  Memgraph offers specific flags to optimize streaming graph updates.

- [Choosing the right Memgraph storage mode](#choosing-the-right-memgraph-storage-mode) <br />
  Guidance on selecting the optimal **storage mode** for high-throughput use cases, depending on whether your focus is
  analytical speed or transactional safety.
  
- [Importing mechanisms](#importing-mechanisms) <br />
  With multithreaded writes, learn how to avoid write-write conflicts. Connect your streaming sources to Memgraph.

- [Enterprise features you might require](#enterprise-features-you-might-require)  <br />
  Understand which **enterprise features** ‚Äî such as high availability, and dynamic graph algorithms will keep your real-time use case smooth.

- [Queries that best suit your workload](#queries-that-best-suit-your-workload)
  Learn how to optimize update queries coming at the database.

- [Memgraph ecosystem](#memgraph-ecosystem)
  Memgraph offers native streaming support for Apache Kafka and Apache Pulsar.

## Choosing the right Memgraph flag set
blahblah

## Choosing the right Memgraph storage mode
blahblah

## Importing mechanisms
blahblah

## Enterprise features you might require
blahblah

## Queries that best suit your workload
blahblah

## Memgraph ecosystem
blahblah

<CommunityLinks/>
